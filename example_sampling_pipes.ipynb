{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from einops import einsum\n",
    "\n",
    "from diffusers import DiffusionPipeline\n",
    "from evotorch import Problem\n",
    "from evotorch.decorators import vectorized\n",
    "from evotorch.algorithms import CMAES, SNES, CEM\n",
    "from evotorch.logging import StdOutLogger, PandasLogger\n",
    "from noise_injection_pipelines.sampling_pipelines import (\n",
    "    SDXLSamplingPipeline,\n",
    "    SD3SamplingPipeline,\n",
    ")\n",
    "from fitness.fitness_fn import (\n",
    "    brightness,\n",
    "    clip_fitness_fn,\n",
    "    compose_fitness_fns,\n",
    "    relative_luminance,\n",
    "    Novelty,\n",
    "    pickscore_fitness_fn,\n",
    "    aesthetic_fitness_fn,\n",
    "    imagereward_fitness_fn,\n",
    ")\n",
    "from evo.vectorized_problem import VectorizedProblem\n",
    "from diffusers.utils import pt_to_pil, numpy_to_pil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from noise_injection_pipelines.noise_injection import (\n",
    "    rotational_transform,\n",
    "    rotational_transform_v2,\n",
    "    multi_axis_rotational_transform_v2,\n",
    "    noise\n",
    ")\n",
    "from noise_injection_pipelines.initialization import randn_intialization, rotation_initalization\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"stabilityai/sdxl-turbo\"\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model_name, torch_dtype=torch.bfloat16, use_safetensors=True\n",
    ").to(\"cuda\")\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_split = 6\n",
    "num_inference_steps = 15\n",
    "noise_scale = 1.0\n",
    "prompt = \"A beautiful landscape painting\"\n",
    "sample_fn = SDXLSamplingPipeline(\n",
    "    pipe,\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    generator=torch.Generator(device=pipe.device).manual_seed(0),\n",
    "    guidance_scale=5.0\n",
    ")\n",
    "\n",
    "image_rew = imagereward_fitness_fn([prompt], device=pipe.device, dtype=pipe.dtype)\n",
    "fit = compose_fitness_fns([image_rew], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scale = 0.01\n",
    "initial_bounds = (-0.1, 0.1)\n",
    "injection_steps = num_inference_steps\n",
    "sample_fn.inject_multiple_noise_scale = noise_scale\n",
    "\n",
    "fitness_fn, inner_fn, centroid, solution_length = rotational_transform(\n",
    "    sample_fn,\n",
    "    fit,\n",
    "    sample_fn.latents.shape,\n",
    "    device=pipe.device,\n",
    "    center=sample_fn.latents,\n",
    "    dtype=pipe.dtype,\n",
    ")\n",
    "\n",
    "problem = VectorizedProblem(\n",
    "    \"max\",\n",
    "    fitness_fn,\n",
    "    solution_length=solution_length,\n",
    "    initial_bounds=initial_bounds,\n",
    "    dtype=np.dtype(\"float32\"),\n",
    "    splits=problem_split,\n",
    "    # initialization=None,\n",
    "    initialization=partial(rotation_initalization, solution_length=solution_length, latents_shape=sample_fn.latents.shape, stdev=0.1),\n",
    ")\n",
    "# searcher = CMAES(problem, stdev_init=1, separable=True, csa_squared=True)\n",
    "searcher = SNES(problem, stdev_init=5)\n",
    "logger = StdOutLogger(searcher)\n",
    "pandas_logger = PandasLogger(searcher)\n",
    "# print(f\"pop. size: {searcher.popsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sample_fn()\n",
    "plt.imshow(numpy_to_pil(a)[0])\n",
    "plt.show()\n",
    "print(fit(a[0]))\n",
    "with torch.no_grad():\n",
    "    for step in range(200):\n",
    "        searcher.step()\n",
    "        best_idx = searcher.population.argbest()\n",
    "        x = searcher.population[best_idx].values\n",
    "\n",
    "        a = inner_fn(x)\n",
    "        plt.imshow(numpy_to_pil(a)[0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDXL Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig\n",
    "from diffusers import UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"stabilityai/sdxl-turbo\"\n",
    "\n",
    "quant_config = DiffusersBitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    model_name,\n",
    "    subfolder=\"unet\",\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model_name, torch_dtype=torch.float16, use_safetensors=True, unet=unet\n",
    ")\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_split = 6\n",
    "num_inference_steps = 15\n",
    "noise_scale = 1.0\n",
    "prompt = \"A small domesticated carnivorous mammal with soft fur, a short snout, and retractable claws. It is widely kept as a pet or for catching mice, and many breeds have been developed.\"\n",
    "sample_fn = SDXLSamplingPipeline(\n",
    "    pipe,\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    generator=torch.Generator(device=pipe.device).manual_seed(0),\n",
    "    guidance_scale=5.0\n",
    ")\n",
    "\n",
    "image_rew = imagereward_fitness_fn([prompt], device=pipe.device, dtype=pipe.dtype)\n",
    "fit = compose_fitness_fns([image_rew], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scale = 0.01\n",
    "initial_bounds = (-0.1, 0.1)\n",
    "injection_steps = num_inference_steps\n",
    "sample_fn.inject_multiple_noise_scale = noise_scale\n",
    "\n",
    "fitness_fn, inner_fn, centroid, solution_length = rotational_transform(\n",
    "    sample_fn,\n",
    "    fit,\n",
    "    sample_fn.latents.shape,\n",
    "    device=pipe.device,\n",
    "    center=sample_fn.latents,\n",
    "    dtype=pipe.dtype,\n",
    ")\n",
    "\n",
    "problem = VectorizedProblem(\n",
    "    \"max\",\n",
    "    fitness_fn,\n",
    "    solution_length=solution_length,\n",
    "    initial_bounds=initial_bounds,\n",
    "    dtype=np.dtype(\"float32\"),\n",
    "    splits=problem_split,\n",
    "    # initialization=None,\n",
    "    initialization=partial(rotation_initalization, solution_length=solution_length, latents_shape=sample_fn.latents.shape, stdev=0.0),\n",
    ")\n",
    "# searcher = CMAES(problem, stdev_init=1, separable=True, csa_squared=True)\n",
    "searcher = SNES(problem, stdev_init=0.1)\n",
    "logger = StdOutLogger(searcher)\n",
    "pandas_logger = PandasLogger(searcher)\n",
    "# print(f\"pop. size: {searcher.popsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sample_fn()\n",
    "plt.imshow(numpy_to_pil(a)[0])\n",
    "plt.show()\n",
    "print(fit(a[0]))\n",
    "with torch.no_grad():\n",
    "    for step in range(200):\n",
    "        searcher.step()\n",
    "        best_idx = searcher.population.argbest()\n",
    "        x = searcher.population[best_idx].values\n",
    "\n",
    "        a = inner_fn(x)\n",
    "        plt.imshow(numpy_to_pil(a)[0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import BitsAndBytesConfig, SD3Transformer2DModel\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "import torch\n",
    "\n",
    "# model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n",
    "model_id = \"tensorart/stable-diffusion-3.5-medium-turbo\"\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model_nf4 = SD3Transformer2DModel.from_pretrained(\n",
    "    model_id,\n",
    "    subfolder=\"transformer\",\n",
    "    quantization_config=nf4_config,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipeline = StableDiffusion3Pipeline.from_pretrained(\n",
    "    model_id, \n",
    "    transformer=model_nf4,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "\n",
    "pipeline.enable_xformers_memory_efficient_attention()\n",
    "pipeline.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A whimsical and creative image depicting a hybrid creature that is a mix of a waffle and a hippopotamus, basking in a river of melted butter amidst a breakfast-themed landscape. It features the distinctive, bulky body shape of a hippo. However, instead of the usual grey skin, the creature's body resembles a golden-brown, crispy waffle fresh off the griddle. The skin is textured with the familiar grid pattern of a waffle, each square filled with a glistening sheen of syrup. The environment combines the natural habitat of a hippo with elements of a breakfast table setting, a river of warm, melted butter, with oversized utensils or plates peeking out from the lush, pancake-like foliage in the background, a towering pepper mill standing in for a tree.  As the sun rises in this fantastical world, it casts a warm, buttery glow over the scene. The creature, content in its butter river, lets out a yawn. Nearby, a flock of birds take flight\"\n",
    "prompt = \"A small domesticated carnivorous mammal with soft fur, a short snout, and retractable claws. It is widely kept as a pet or for catching mice, and many breeds have been developed.\"\n",
    "\n",
    "sample_fn = SD3SamplingPipeline(\n",
    "    pipeline,\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=15,\n",
    "    generator=torch.Generator(device=pipeline.device).manual_seed(1),\n",
    "    guidance_scale=4.5,\n",
    "    add_noise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rew = imagereward_fitness_fn(\n",
    "    [prompt], device=pipeline.device, dtype=pipeline.dtype\n",
    ")\n",
    "fit = compose_fitness_fns([image_rew], [1])\n",
    "\n",
    "mean_scale = 0.000\n",
    "initial_bounds = (-1, 1)\n",
    "problem_split = 4\n",
    "\n",
    "# fitness_fn, inner_fn, centroid, solution_length = rotational_transform(\n",
    "#     sample_fn,\n",
    "#     fit,\n",
    "#     sample_fn.latents.shape,\n",
    "#     device=pipeline.device,\n",
    "#     center=sample_fn.latents,\n",
    "#     dtype=pipeline.dtype,\n",
    "# )\n",
    "\n",
    "fitness_fn, inner_fn, centroid, solution_length = noise(\n",
    "    sample_fn,\n",
    "    fit,\n",
    "    sample_fn.latents.shape,\n",
    "    device=pipeline.device,\n",
    "    dtype=pipeline.dtype,\n",
    ")\n",
    "\n",
    "\n",
    "problem = VectorizedProblem(\n",
    "    \"max\",\n",
    "    fitness_fn,\n",
    "    solution_length=solution_length,\n",
    "    initial_bounds=initial_bounds,\n",
    "    dtype=np.dtype(\"float32\"),\n",
    "    splits=problem_split,\n",
    "    # initialization=partial(rotation_initalization, solution_length=solution_length, latents_shape=sample_fn.latents.shape, stdev=0.00),\n",
    "    initialization=partial(randn_intialization, stdev=1),\n",
    "    device=pipeline.device,\n",
    ")\n",
    "searcher = CMAES(\n",
    "    problem,\n",
    "    stdev_init=0.5,\n",
    "    separable=True,\n",
    "    center_init=sample_fn.latents.flatten(),\n",
    "    # center_init=torch.zeros_like(sample_fn.latents.flatten()),\n",
    "    # csa_squared=True,\n",
    ")\n",
    "# searcher = SNES(problem, stdev_init=0.1, center_init=sample_fn.latents.flatten())\n",
    "logger = StdOutLogger(searcher)\n",
    "pandas_logger = PandasLogger(searcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sample_fn()\n",
    "plt.imshow(numpy_to_pil(a)[0])\n",
    "plt.show()\n",
    "print(fit(a[0]))\n",
    "with torch.no_grad():\n",
    "    for step in range(50):\n",
    "        searcher.step()\n",
    "        best_idx = searcher.population.argbest()\n",
    "        x = searcher.population[best_idx].values\n",
    "\n",
    "        a = inner_fn(x)\n",
    "        plt.imshow(numpy_to_pil(a)[0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff-traf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
